{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a70dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from google.cloud import bigquery \n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta , date \n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176dbed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#May have some issues running this code to retrieve old data due to API issues by snscrape library\n",
    "def mapper(key):\n",
    "    if key == 'grab':\n",
    "        return '#grab'\n",
    "    elif key =='dbs':\n",
    "        return 'dbs AND bank'\n",
    "    else:\n",
    "        return key\n",
    "# Specify the search criteria\n",
    "tickers=[\n",
    "    ('d05.SI', 'dbs'),\n",
    "    ('SE', 'garena'),\n",
    "    ('SE', 'shopee'),\n",
    "    ('039.SI', 'ocbc'),\n",
    "    ('U11.SI', 'uob'),\n",
    "    ('Z74.SI', 'singtel'),\n",
    "    ('F34.SI', 'wilmar'),\n",
    "    ('C6L.SI', 'singapore airlines'),\n",
    "    ('GRAB', 'grab'),\n",
    "    ('G13.SI', 'genting'),\n",
    "    ('C38U.SI', 'capitaland'),\n",
    "    ('G07.SI', 'great eastern'),\n",
    "    ('C07.SI', 'jardine'),\n",
    "    ('A17U.SI', 'ascendas'),\n",
    "    ('S63.SI', 'st engineering'),\n",
    "    ('BN4.SI', 'keppel')\n",
    "]\n",
    "\n",
    "\n",
    "# Create an empty list to store the tweets\n",
    "tweets = []\n",
    "for tup in tickers:\n",
    "    keyword = mapper(tup[1])\n",
    "     #can use OR to specify other things #hashtag also can\n",
    "    start_date = date(2022, 2, 18)\n",
    "    end_date = date(2023, 4, 19)\n",
    "    user = ''\n",
    "\n",
    "    # Create a list of dates between start_date and end_date\n",
    "    delta = timedelta(days=1)\n",
    "    date_range = pd.date_range(start_date, end_date, freq='D').tolist()\n",
    "\n",
    "\n",
    "    #limit of tweets per day\n",
    "    limit = 100\n",
    "\n",
    "    # Loop over each day in the date range and retrieve X tweets per day\n",
    "    #if count == limit or when the loop ends\n",
    "    for i in range(len(date_range)):\n",
    "        day = date_range[i].strftime('%Y-%m-%d')\n",
    "        dayNext = (date_range[i] + timedelta(days = 1)).strftime('%Y-%m-%d')\n",
    "        query = f'{keyword} since:{day} until:{dayNext} lang:en'\n",
    "        count = 0\n",
    "        for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "            if (count == limit):\n",
    "                break\n",
    "            tweets.append([tup[1], tup[0], tweet.date, tweet.content, tweet.likeCount])\n",
    "            count+= 1\n",
    "        print(f'{tup[1]}_{day}: {count} total tweets retrieved')\n",
    "\n",
    "# Convert the list of tweets to a Pandas DataFrame\n",
    "rawData = pd.DataFrame(tweets, columns=['Ticker_Name', 'Ticker', 'Datetime', 'Text', 'Like_Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0131d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "        # method for cleaning tweets used in clean_twitter_data dag\n",
    "\n",
    "        tweet = re.sub(r'http\\S+', '', tweet)\n",
    "        # Remove mentions\n",
    "        tweet = re.sub(r'@[A-Za-z0-9_]+', '', tweet)\n",
    "        # Remove hashtags\n",
    "        tweet = re.sub(r'#', '', tweet)\n",
    "        # Remove non-alphabetic characters\n",
    "        tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
    "        # Convert to lowercase\n",
    "        tweet = tweet.lower()\n",
    "        # Remove stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = tweet.split()\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "\n",
    "def splitScore(df):\n",
    "    df['negative'] = df['Score'].apply(lambda x: x.get('neg'))\n",
    "    df['neutral'] = df['Score'].apply(lambda x: x.get('neu'))\n",
    "    df['positive'] = df['Score'].apply(lambda x: x.get('pos'))\n",
    "    df['compound'] = df['Score'].apply(lambda x: x.get('compound'))\n",
    "    return df\n",
    "\n",
    "def weighted_avg(df):\n",
    "    weights = df['Like_Count'] + 1\n",
    "    return (df['compound'] * weights).sum() / weights.sum()\n",
    "\n",
    "#fill missing dates with no Weighted_Compound_Score with 0\n",
    "def fillMissing(aggregated_data):\n",
    "    tickers = ['dbs',\n",
    "                 'garena',\n",
    "                 'shopee',\n",
    "                 'ocbc',\n",
    "                 'uob',\n",
    "                 'singtel',\n",
    "                 'wilmar',\n",
    "                 'singapore airlines',\n",
    "                 'grab',\n",
    "                 'genting',\n",
    "                 'capitaland',\n",
    "                 'great eastern',\n",
    "                 'jardine',\n",
    "                 'ascendas',\n",
    "                 'st engineering',\n",
    "                 'keppel']\n",
    "\n",
    "    tickerMapper = {'dbs': 'd05.SI',\n",
    "                     'garena': 'SE',\n",
    "                     'shopee': 'SE',\n",
    "                     'ocbc': '039.SI',\n",
    "                     'uob': 'U11.SI',\n",
    "                     'singtel': 'Z74.SI',\n",
    "                     'wilmar': 'F34.SI',\n",
    "                     'singapore airlines': 'C6L.SI',\n",
    "                     'grab': 'GRAB',\n",
    "                     'genting': 'G13.SI',\n",
    "                     'capitaland': 'C38U.SI',\n",
    "                     'great eastern': 'G07.SI',\n",
    "                     'jardine': 'C07.SI',\n",
    "                     'ascendas': 'A17U.SI',\n",
    "                     'st engineering': 'S63.SI',\n",
    "                     'keppel': 'BN4.SI'}\n",
    "\n",
    "    dates = pd.date_range(start='2023-02-18', end='2023-04-19', freq='D') # date range of concern\n",
    "    df1 = pd.DataFrame(list(np.ndindex((len(tickers), len(dates)))), columns=['Ticker_idx', 'Date_idx'])\n",
    "    df1['Ticker_Name'] = df1['Ticker_idx'].apply(lambda x: tickers[x])\n",
    "    df1['Date'] = df1['Date_idx'].apply(lambda x: dates[x])\n",
    "    df1 = df1.drop(['Ticker_idx', 'Date_idx'], axis=1)\n",
    "\n",
    "    df1['Ticker'] = df1['Ticker_Name'].apply(lambda x: tickerMapper[x])\n",
    "    merged_data = pd.merge(df1, aggregated_data, on = ['Ticker_Name', 'Ticker', 'Date'], how = 'left')\n",
    "    merged_data['Weighted_Compound_Score'] = merged_data['Weighted_Compound_Score'].fillna(0)\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818cdae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker_Name</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Like_Count</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@MrRich @saifyakhtar @Uber @GrabMY @pertamadig...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-18 05:43:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@idcrypto7 Hi, we are replying from DBS India....</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-18 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@shimshiper Hi, we are replying from DBS India...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-19 04:20:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>I have not yet checked my bank on my other dev...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-20 10:46:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@JOngkowidjaja Hi, we are replying from DBS In...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-21 04:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>One of my friends from high school was murdere...</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-04-19 12:35:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>He truly thinks his BS will be swallowed whole...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 14:53:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>He truly thinks his BS will be swallowed whole...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 14:53:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>Doing what they do the best……stirring the pot ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 22:03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>Doing what they do the best……stirring the pot ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 22:03:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9331 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker_Name  Ticker                                              Texts  \\\n",
       "0            dbs  d05.SI  @MrRich @saifyakhtar @Uber @GrabMY @pertamadig...   \n",
       "1            dbs  d05.SI  @idcrypto7 Hi, we are replying from DBS India....   \n",
       "2            dbs  d05.SI  @shimshiper Hi, we are replying from DBS India...   \n",
       "3            dbs  d05.SI  I have not yet checked my bank on my other dev...   \n",
       "4            dbs  d05.SI  @JOngkowidjaja Hi, we are replying from DBS In...   \n",
       "...          ...     ...                                                ...   \n",
       "9326      keppel  BN4.SI  One of my friends from high school was murdere...   \n",
       "9327      keppel  BN4.SI  He truly thinks his BS will be swallowed whole...   \n",
       "9328      keppel  BN4.SI  He truly thinks his BS will be swallowed whole...   \n",
       "9329      keppel  BN4.SI  Doing what they do the best……stirring the pot ...   \n",
       "9330      keppel  BN4.SI  Doing what they do the best……stirring the pot ...   \n",
       "\n",
       "      Like_Count            Datetime  \n",
       "0              1 2023-02-18 05:43:20  \n",
       "1              0 2023-02-18 09:00:00  \n",
       "2              0 2023-02-19 04:20:01  \n",
       "3              0 2023-02-20 10:46:10  \n",
       "4              0 2023-02-21 04:25:00  \n",
       "...          ...                 ...  \n",
       "9326           3 2023-04-19 12:35:33  \n",
       "9327           0 2023-04-19 14:53:05  \n",
       "9328           0 2023-04-19 14:53:05  \n",
       "9329           0 2023-04-19 22:03:46  \n",
       "9330           0 2023-04-19 22:03:46  \n",
       "\n",
       "[9331 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data here are those that are successfully scraped previously by snscrape from 18/2/2023-19/4/2023\n",
    "raw_data = pd.read_csv('raw_data.csv')\n",
    "raw_data['Datetime'] = pd.to_datetime(raw_data['Datetime'])\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634920b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker_Name</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Like_Count</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Texts_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@MrRich @saifyakhtar @Uber @GrabMY @pertamadig...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-18 05:43:20</td>\n",
       "      <td>managed catch last minutes interview agree tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@idcrypto7 Hi, we are replying from DBS India....</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-18 09:00:00</td>\n",
       "      <td>hi replying dbs india please share details us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@shimshiper Hi, we are replying from DBS India...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-19 04:20:01</td>\n",
       "      <td>hi replying dbs india please share details us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>I have not yet checked my bank on my other dev...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-20 10:46:10</td>\n",
       "      <td>yet checked bank device ive resting recent hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@JOngkowidjaja Hi, we are replying from DBS In...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-21 04:25:00</td>\n",
       "      <td>hi replying dbs india query pertaining dbs ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>One of my friends from high school was murdere...</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-04-19 12:35:33</td>\n",
       "      <td>one friends high school murdered going wrong h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>He truly thinks his BS will be swallowed whole...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 14:53:05</td>\n",
       "      <td>truly thinks bs swallowed whole hes stupid can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>He truly thinks his BS will be swallowed whole...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 14:53:05</td>\n",
       "      <td>truly thinks bs swallowed whole hes stupid can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>Doing what they do the best……stirring the pot ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 22:03:46</td>\n",
       "      <td>beststirring pot chaos amp confusion humans sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>Doing what they do the best……stirring the pot ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 22:03:46</td>\n",
       "      <td>beststirring pot chaos amp confusion humans sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9331 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker_Name  Ticker                                              Texts  \\\n",
       "0            dbs  d05.SI  @MrRich @saifyakhtar @Uber @GrabMY @pertamadig...   \n",
       "1            dbs  d05.SI  @idcrypto7 Hi, we are replying from DBS India....   \n",
       "2            dbs  d05.SI  @shimshiper Hi, we are replying from DBS India...   \n",
       "3            dbs  d05.SI  I have not yet checked my bank on my other dev...   \n",
       "4            dbs  d05.SI  @JOngkowidjaja Hi, we are replying from DBS In...   \n",
       "...          ...     ...                                                ...   \n",
       "9326      keppel  BN4.SI  One of my friends from high school was murdere...   \n",
       "9327      keppel  BN4.SI  He truly thinks his BS will be swallowed whole...   \n",
       "9328      keppel  BN4.SI  He truly thinks his BS will be swallowed whole...   \n",
       "9329      keppel  BN4.SI  Doing what they do the best……stirring the pot ...   \n",
       "9330      keppel  BN4.SI  Doing what they do the best……stirring the pot ...   \n",
       "\n",
       "      Like_Count            Datetime  \\\n",
       "0              1 2023-02-18 05:43:20   \n",
       "1              0 2023-02-18 09:00:00   \n",
       "2              0 2023-02-19 04:20:01   \n",
       "3              0 2023-02-20 10:46:10   \n",
       "4              0 2023-02-21 04:25:00   \n",
       "...          ...                 ...   \n",
       "9326           3 2023-04-19 12:35:33   \n",
       "9327           0 2023-04-19 14:53:05   \n",
       "9328           0 2023-04-19 14:53:05   \n",
       "9329           0 2023-04-19 22:03:46   \n",
       "9330           0 2023-04-19 22:03:46   \n",
       "\n",
       "                                          Texts_Cleaned  \n",
       "0     managed catch last minutes interview agree tak...  \n",
       "1     hi replying dbs india please share details us ...  \n",
       "2     hi replying dbs india please share details us ...  \n",
       "3     yet checked bank device ive resting recent hea...  \n",
       "4     hi replying dbs india query pertaining dbs ind...  \n",
       "...                                                 ...  \n",
       "9326  one friends high school murdered going wrong h...  \n",
       "9327  truly thinks bs swallowed whole hes stupid can...  \n",
       "9328  truly thinks bs swallowed whole hes stupid can...  \n",
       "9329  beststirring pot chaos amp confusion humans sh...  \n",
       "9330  beststirring pot chaos amp confusion humans sh...  \n",
       "\n",
       "[9331 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = raw_data.copy()\n",
    "processed_data['Texts_Cleaned'] = processed_data['Texts'].apply(lambda x: clean_tweet(x))\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980983c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker_Name</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Like_Count</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Texts_Cleaned</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@MrRich @saifyakhtar @Uber @GrabMY @pertamadig...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-18 05:43:20</td>\n",
       "      <td>managed catch last minutes interview agree tak...</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>2023-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@idcrypto7 Hi, we are replying from DBS India....</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-18 09:00:00</td>\n",
       "      <td>hi replying dbs india please share details us ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>2023-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@shimshiper Hi, we are replying from DBS India...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-19 04:20:01</td>\n",
       "      <td>hi replying dbs india please share details us ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>2023-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>I have not yet checked my bank on my other dev...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-20 10:46:10</td>\n",
       "      <td>yet checked bank device ive resting recent hea...</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.0531</td>\n",
       "      <td>2023-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dbs</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>@JOngkowidjaja Hi, we are replying from DBS In...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-21 04:25:00</td>\n",
       "      <td>hi replying dbs india query pertaining dbs ind...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>One of my friends from high school was murdere...</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-04-19 12:35:33</td>\n",
       "      <td>one friends high school murdered going wrong h...</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.6597</td>\n",
       "      <td>2023-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>He truly thinks his BS will be swallowed whole...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 14:53:05</td>\n",
       "      <td>truly thinks bs swallowed whole hes stupid can...</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.5859</td>\n",
       "      <td>2023-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>He truly thinks his BS will be swallowed whole...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 14:53:05</td>\n",
       "      <td>truly thinks bs swallowed whole hes stupid can...</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.5859</td>\n",
       "      <td>2023-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>Doing what they do the best……stirring the pot ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 22:03:46</td>\n",
       "      <td>beststirring pot chaos amp confusion humans sh...</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>2023-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>keppel</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>Doing what they do the best……stirring the pot ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-19 22:03:46</td>\n",
       "      <td>beststirring pot chaos amp confusion humans sh...</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>2023-04-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9331 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker_Name  Ticker                                              Texts  \\\n",
       "0            dbs  d05.SI  @MrRich @saifyakhtar @Uber @GrabMY @pertamadig...   \n",
       "1            dbs  d05.SI  @idcrypto7 Hi, we are replying from DBS India....   \n",
       "2            dbs  d05.SI  @shimshiper Hi, we are replying from DBS India...   \n",
       "3            dbs  d05.SI  I have not yet checked my bank on my other dev...   \n",
       "4            dbs  d05.SI  @JOngkowidjaja Hi, we are replying from DBS In...   \n",
       "...          ...     ...                                                ...   \n",
       "9326      keppel  BN4.SI  One of my friends from high school was murdere...   \n",
       "9327      keppel  BN4.SI  He truly thinks his BS will be swallowed whole...   \n",
       "9328      keppel  BN4.SI  He truly thinks his BS will be swallowed whole...   \n",
       "9329      keppel  BN4.SI  Doing what they do the best……stirring the pot ...   \n",
       "9330      keppel  BN4.SI  Doing what they do the best……stirring the pot ...   \n",
       "\n",
       "      Like_Count            Datetime  \\\n",
       "0              1 2023-02-18 05:43:20   \n",
       "1              0 2023-02-18 09:00:00   \n",
       "2              0 2023-02-19 04:20:01   \n",
       "3              0 2023-02-20 10:46:10   \n",
       "4              0 2023-02-21 04:25:00   \n",
       "...          ...                 ...   \n",
       "9326           3 2023-04-19 12:35:33   \n",
       "9327           0 2023-04-19 14:53:05   \n",
       "9328           0 2023-04-19 14:53:05   \n",
       "9329           0 2023-04-19 22:03:46   \n",
       "9330           0 2023-04-19 22:03:46   \n",
       "\n",
       "                                          Texts_Cleaned  negative  neutral  \\\n",
       "0     managed catch last minutes interview agree tak...     0.064    0.675   \n",
       "1     hi replying dbs india please share details us ...     0.000    0.781   \n",
       "2     hi replying dbs india please share details us ...     0.000    0.712   \n",
       "3     yet checked bank device ive resting recent hea...     0.172    0.662   \n",
       "4     hi replying dbs india query pertaining dbs ind...     0.000    0.797   \n",
       "...                                                 ...       ...      ...   \n",
       "9326  one friends high school murdered going wrong h...     0.403    0.430   \n",
       "9327  truly thinks bs swallowed whole hes stupid can...     0.284    0.532   \n",
       "9328  truly thinks bs swallowed whole hes stupid can...     0.284    0.532   \n",
       "9329  beststirring pot chaos amp confusion humans sh...     0.246    0.478   \n",
       "9330  beststirring pot chaos amp confusion humans sh...     0.246    0.478   \n",
       "\n",
       "      positive  compound        Date  \n",
       "0        0.261    0.7506  2023-02-18  \n",
       "1        0.219    0.5574  2023-02-18  \n",
       "2        0.288    0.7269  2023-02-19  \n",
       "3        0.166   -0.0531  2023-02-20  \n",
       "4        0.203    0.5574  2023-02-21  \n",
       "...        ...       ...         ...  \n",
       "9326     0.167   -0.6597  2023-04-19  \n",
       "9327     0.184   -0.5859  2023-04-19  \n",
       "9328     0.184   -0.5859  2023-04-19  \n",
       "9329     0.276    0.2263  2023-04-19  \n",
       "9330     0.276    0.2263  2023-04-19  \n",
       "\n",
       "[9331 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "processed_data['Score'] = processed_data['Texts_Cleaned'].apply(lambda x: sia.polarity_scores(x))\n",
    "processed_data = splitScore(processed_data)\n",
    "processed_data.drop(columns = {'Score'}, inplace = True)\n",
    "processed_data['Date'] = processed_data['Datetime'].apply(lambda x: x.date())\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7516b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker_Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Weighted_Compound_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dbs</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>0.686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbs</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>0.726900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbs</td>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>-0.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbs</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>0.110959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dbs</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>d05.SI</td>\n",
       "      <td>0.120400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>keppel</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>-0.034180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>keppel</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>0.017633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>keppel</td>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>0.063433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>keppel</td>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>-0.119913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>keppel</td>\n",
       "      <td>2023-04-19</td>\n",
       "      <td>BN4.SI</td>\n",
       "      <td>-0.160405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>976 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker_Name       Date  Ticker  Weighted_Compound_Score\n",
       "0           dbs 2023-02-18  d05.SI                 0.686200\n",
       "1           dbs 2023-02-19  d05.SI                 0.726900\n",
       "2           dbs 2023-02-20  d05.SI                -0.053100\n",
       "3           dbs 2023-02-21  d05.SI                 0.110959\n",
       "4           dbs 2023-02-22  d05.SI                 0.120400\n",
       "..          ...        ...     ...                      ...\n",
       "971      keppel 2023-04-15  BN4.SI                -0.034180\n",
       "972      keppel 2023-04-16  BN4.SI                 0.017633\n",
       "973      keppel 2023-04-17  BN4.SI                 0.063433\n",
       "974      keppel 2023-04-18  BN4.SI                -0.119913\n",
       "975      keppel 2023-04-19  BN4.SI                -0.160405\n",
       "\n",
       "[976 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data = processed_data.groupby(['Ticker_Name', 'Ticker', 'Date'], as_index = False).apply(weighted_avg)\n",
    "aggregated_data.rename(columns = {None: 'Weighted_Compound_Score'}, inplace = True)\n",
    "aggregated_data['Date'] = pd.to_datetime(aggregated_data['Date'] )\n",
    "aggregated_data = fillMissing(aggregated_data)\n",
    "aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10fea934",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = r'C:\\Users\\hsinz\\Desktop\\nus\\Y3S2\\IS3107\\Proj\\sharedkey.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bc9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openfile=open(key)\n",
    "jsondata=json.load(openfile)\n",
    "openfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b63430",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_path = key\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= credentials_path\n",
    "client = bigquery.Client()\n",
    "project_id = jsondata['project_id']\n",
    "staging_table_id = project_id + \".twitter_data.stock_info\"\n",
    "process_table_id = project_id + \".twitter_data.stock_processed\"\n",
    "aggregated_table_id = project_id + \".twitter_data.stock_aggregated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc17fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushData():  \n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        encoding='UTF-8',\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    )\n",
    "    job = client.load_table_from_dataframe(raw_data, staging_table_id, job_config=job_config)\n",
    "    job = client.load_table_from_dataframe(processed_data, process_table_id, job_config=job_config)\n",
    "    job = client.load_table_from_dataframe(aggregated_data, aggregated_table_id, job_config=job_config)\n",
    "\n",
    "    job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa9f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pushData()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
